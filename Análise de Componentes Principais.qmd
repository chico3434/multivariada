---
title: "Análise de Componentes Principais"
author: "Francisco Rubens e Julio Cesar"
format: pdf
---

## Análise descritiva

Fazendo primeiro a análise descritiva dos dados.  

```{r}
data(iris)
head(iris, 3)
diris=iris[,1:4]
(summary(diris))
```

Acima tem-se a média, os quartis e os mínimos e máximos das variáveis.  
Nota-se que o comprimento da pétala possui uma distribuição bem assimétrica em torno da média, pois a mediana é 4,35 e a média é 3,76.  

```{r}
(varian=var(diris))
boxplot(diris,col="cyan")
(correl=cor(diris))
plot(diris,col="red")
```


Podemos ver pelos gráficos de correlação e a matriz de correlação uma correlação forte, principalmente, entre o comprimento da pétala com a largura da pétala (0,96), mas também vemos correlação forte entre comprimento da sépala com comprimento da pétala (0,87) e entre comprimento da sépala e largura da pétala (0,81).


## Análise de componentes principais

Começando a análise de componentes principais serão achados os autovalores e autovetores da matriz de covariância e da matriz de correlação.

```{r}
(autov <- eigen(varian))
(autoc <- eigen(correl))
```

Os auvalores são as variâncias dos componentes principais. Para a matriz de covariância são:  
var($Y_1$) = 4,22824171  
var($Y_2$) = 0,24267075  
var($Y_3$) = 0,07820950  
var($Y_4$) = 0,02383509  

Para a matriz de correlação:  
var($Y_1$) = 2,91849782  
var($Y_2$) = 0,91403047  
var($Y_3$) = 0,14675688  
var($Y_4$) = 0,02071484  

Para se ter noção da proporção da variância das componentes:  

```{r}
autov$values[1:4]/sum(autov$values)
autoc$values[1:4]/sum(autoc$values)
```

Nota-se que para se ter ao menos 99% da proporção da variância das componentes, não é necessária a componente principal 4 para os dois métodos.  
O método usando a matriz de correlação é o método quando padroniza as variáveis, pois padronizando as variáveis a matriz de covariância é igual a matriz de correlação.  

```{r}
padiris=scale(diris)
(varianp=var(padiris))
correl-varianp
```

É possível usar a função `prcomp` para simplificar o processo de análise de componentes principais.  

```{r}
(cp=prcomp(diris)) # sem padronização (usa matriz de covariância)
(cp1=prcomp(diris,scale=TRUE)) # com padronização (usa matriz de correlação)

summary(cp)
summary(cp1)
```
Nota-se que as proporções de variâncias são as mesmas achadas pelos autovalores, porém esse método retorna também a proporção acumulada. Com isso podemos ver a diferença entre padronizar ou não. E para esses dados podemos ver que, sem padronizar, aproximadamente 98% da variação são explicadas pelas componentes principais 1 e 2, e padronizando, aproximadamente 96% são explicadas pelas CP1 e CP2. Mas a principal diferença padronizando ou não está na CP1, que padronizando cai de 92,5% para 73%. O que faria diferença se fosse adotar o uso de componentes principais que expliquem ao menos 90% da variabilidade.  

```{r}
par(mfrow=c(1,2))
plot(cp,col="red", main="Sem padronizar")
plot(cp1,col="blue", main="Padronizada")
```
Pelos gráficos acima é possível perceber o impacto na proporção das variâncias quando se padroniza as variáveis. A CP1 continua tendo um grande impacto na variância total, mas a CP2 já tem um aumento expressivo quando se padroniza.

